---
title: "10x scRNAseq Analysis - PBMC"
author: "Lauren Stein"
runtime: shiny

---
```{r echo=FALSE, warning=FALSE}
#Install Dependencies
library(dplyr)
library(Seurat)
library(patchwork)
```
```{r}
# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "filtered_gene_bc_matrices/hg19/")
# Initialize the Seurat object with the raw (non-normalized data).
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k", min.cells = 3, min.features = 200)
dim(pbmc)
```

# Standard Pre-Processing Workflow
Selection and filtration of cells based on QC metrics, data normalization and scaling, and detection of highly variable features.  
[Common QC Merics](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4758103/)   

1. Number of unique genes detected in each cell
    + Low-quality cells or empty droplets will often have very few genes  
    + Cell doublets or multiplets may exhibit an aberrantly high gene count  
2. Total number of molecules detected within a cell (correlates strongly with unique genes)
3. Percentage of reads that map to the mitochondrial genome
    + Low-quality / dying cells often exhibit extensive mitochondrial contamination  
    + Calculate mitochondrial QC metrics with the PercentageFeatureSet function, which calculates the percentage of counts originating from a set of features  
    + Use the set of all genes starting with MT- as a set of mitochondrial genes  

```{r}
# The [[ operator can add columns to object metadata. This is a great place to stash QC stats
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")

#Show QC metrics for the first 5 cells with additional column
head(pbmc@meta.data, 5)
```

## Visualize QC Metrics
```{r}
# Visualize QC metrics as a violin plot
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
```

```{r}
# FeatureScatter  used to visualize feature-feature relationships, but can be used
# for anything calculated by the object, i.e. columns in object metadata, PC scores etc.

plot1 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot1 + plot2
```

```{r}
# Create a subset of the data with unique feature counts >2500 or less than 200 and less than 5% mitochondrial counts
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)
```

## Normalize the Data
Apply a global-scaling normalization method "LogNormalize":normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result.  
**Normalized values are stored in `pbmc[["RNA"]]@data`**
```{r}
#Default values provided aka pbmc <- NormalizeData(pbmc)
pbmc <- NormalizeData(pbmc, normalization.method = "LogNormalize", scale.factor = 10000)
```

## Identify highly variable features **feature selection**  
* Calculate subset of features with high cell-to-cell variation
    + Enables easier detection of biological signal-to-noise ration [ref](https://www.nature.com/articles/nmeth.2645)
    + Utilizes the `FindVariableFeatures` Function
    + Seurat3 procedure directly models the mean-variance relationship inherent in single-cell data [ref](https://www.biorxiv.org/content/early/2018/11/02/460147.full.pdf)
    + Default returns 2,000 features per dataset ()
```{r}
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(pbmc), 10)

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE, xnudge = 0, ynudge = 0)
plot1 + plot2
```

## Scaling the data

* Apply linear transformation using the `ScaleData` function
    + Standard preprocessing **prior** to dimensional reduction technique
    + Shifts gene expression so **mean** expression across cells is 0
    + Scales gene expression so **variance** across cells is 1 *equal weight in downstream analysis, prevents highly expressed genes from skewing the analysis*
    + results stored in `pbmc[["RNA"]]@scale.data`.
* Important Notes 
    + Scaling is only necessary for genes used as **input** for dimensional reduction
    + To scale on previously identified variable features (2,000 by default) remove `features` from syntax
    + Problematic approach for Seurat heatmaps via `DoHeatmap` becuase some genes may **not** be scaled 
    
```{r}
all.genes <- rownames(pbmc)
pbmc <- ScaleData(pbmc, features = all.genes)
```

## Perform Linear Dimensional Reduction
Dimensionality reduction refers to techniques that reduce the number of input variables in a dataset. More input features often make a modeling task more challenging to model, more generally referred to as the curse of dimensionality. Allows for effective noise removal and facilitate many downstream analyses that include cell clustering and lineage reconstruction.  

* Principal Component Analysis (PAC): Data preparation technique to create a projection of a dataset prior to fitting a model *Linear Discriment Analysis (LDA) alternative methodology not used here*
![PAC](https://miro.medium.com/max/1024/1*vfLvJF8wHaQjDaWv6Mab2w.png)
* input = previously determined variable features
    + use `features` argument to choose a different subset
* Seurat provides multiple ways to visualize cells and features that **define** the PCA such as `VizDimReduction`, `DimPlot`, `DimHeatmap`
```{r}
# Perform PCA on dataset 
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))

# 1. Examine PCA Results
print(pbmc[["pca"]], dims = 1:5, nfeatures = 5)
```
```{r}
# 2. Visualize PCA results
VizDimLoadings(pbmc, dims = 1:2, reduction = "pca")
```
```{r}
# 3. Plot PCA results
DimPlot(pbmc, reduction = "pca")
```
  * Heatmap of PCA results is a great way to explore primary sourcs of heteorgenity in the dataset
  * Aid in deciding which PCs to include for further downstream analysis 
  * Cells and features are ordered according to their PCA score 
  * add `cells` argument to plot specify '**extreme cells**' on both ends of specture. Speeds up processing for very large datasets 
  * Tool for exploring correlated feature sets
  
```{r}
# 4. Heatmaps of PCA results
DimHeatmap(pbmc, dims = 1, cells = 500, balanced = TRUE)
```
```{r}
DimHeatmap(pbmc, dims = 1:15, cells = 500, balanced = TRUE)
```

# Determine the dimensionality of the dataset
* Seurat clusters cells based on PCA scores
    + Overcome the extensive technical noise in any single feature for scRNA-seq data
    + Each PC essentially representing a 'metafeature' that combines information across a correlated feature set.
    + Top PC represent a robust compression of the dataset. 

*How many componenets should we choose to include? 10? 20? 100?*  

* [Macosko et al](https://www.cell.com/fulltext/S0092-8674(15)00549-8), implemented a resampling test inspired by the JackStraw procedure. 
    + Randomly permute a subset of the data (1% by default) and rerun PCA, constructing a 'null distribution' of feature scores, and repeat this procedure. 
    + Identify 'significant' PCs as those who have a strong enrichment of low p-value features.
```{r}
# NOTE: This process can take a long time for big datasets, comment out for expediency. More
# approximate techniques such as those implemented in ElbowPlot() can be used to reduce
# computation time
pbmc <- JackStraw(pbmc, num.replicate = 100)
pbmc <- ScoreJackStraw(pbmc, dims = 1:20)
```
    
* `JackStrawPlot` visualization tool for comparing the distribution of p-values for each PC with a uniform distribution (dashed line)
    + 'Significant' PCs will show a strong enrichment of features with low p-values (solid curve above the dashed line)
```{r warning=FALSE}
JackStrawPlot(pbmc, dims = 1:15)
```

  
* `ElbowPlot`ranking of PCs based on the percentage of variance explained by each one
```{r}
ElbowPlot(pbmc)
```

## Dimensionality Best Practices
Identifying true dimentionality is challenging! Really an art-form  
  1. Supervised exploration of PCs to determine relevant sources of heterogeneity, and used in conjunction with GSEA (for example)
  2.  Implements a statistical test based on a random null model. Time-consuming for large datasets and may not return a clear PC cutoff
  3. Repeat downstrem analysis with different PCs and determine whether the results differ significantly (they shouldn't)
  4. Err on the *higher* side when choosing a parameter
  
# Clustering
Seurat v3 is a graph-based clustering approach using **distance metric**driving analysis (based on previously identified PCs) is the same
  * References for new clustering approaches [scRNA-seq data](https://academic.oup.com/bioinformatics/article/31/12/1974/214505) and [CyTOF data](https://pubmed.ncbi.nlm.nih.gov/26095251/)
  * **K-nearest neighbor** clustering with based on similar feature expression patterns then partition into highly interconnected 'quasicliques' or 'communities'
  1. `FindNeighbors` function: KNN based on euclidean distance in PCA space then apply Jaccard similarity to refine edge weights between any two cells based on shared overlap within local neighborhood. Input is the prevedinied dimensionality of the dataset (first 10 PCs)
  2. `FindClusters`: Optimize the standard modularity function that applies modularity optimization techniques (Louvain algorithm - default, or SLM) to iteratively group cels together.
    +  resolution parameter sets granularity of downsteram function - incr values = greater number of clusters
    +  good starting point 0.4 to 1.2 for a dataset around 3K cells in which optimal resolution increases for larger datasets
    +  `Idents` function to find clusters

```{r}
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- FindClusters(pbmc, resolution = 0.5)
```
```{r}
# Look at cluster IDs of the first 5 cells
head(Idents(pbmc), 5)
```

# Run non-linear dimensional reduciton (UMAP/tSNE)
Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.

```{r}
# If UMAP not installed use 
# reticulate::py_install(packages ='umap-learn')
pbmc <- RunUMAP(pbmc, dims = 1:10)
```
```{r}
# note set `label = TRUE` or use the LabelClusters function to help label
# individual clusters
DimPlot(pbmc, reduction = "umap", label = TRUE)
```
```{r}
# Save file 
saveRDS(pbmc, file = "pbmc_results.rds")
```

